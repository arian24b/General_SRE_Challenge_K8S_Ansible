name: CI/CD Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      deploy_infrastructure:
        description: "Deploy infrastructure"
        type: boolean
        default: false

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository_owner }}/general-sre-challenge-k8s-ansible-api

jobs:
  # ============= CONTINUOUS INTEGRATION =============
  lint-and-test:
    name: Lint & Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Install dependencies
        run: |
          cd application/api
          uv sync --frozen

      - name: Run linting
        run: |
          cd application/api
          uv run ruff check .

      - name: Run tests
        run: |
          cd application/api
          uv run pytest --cov=app --cov-report=xml --cov-report=term

      - name: Upload coverage
        if: always()
        uses: codecov/codecov-action@v5
        with:
          file: ./application/api/coverage.xml
          flags: unittests

  validate-manifests:
    name: Validate Kubernetes Manifests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: "v3.14.0"

      - name: Lint Helm charts
        run: |
          cd application/helm
          helm dependency update
          helm lint .

      - name: Validate Helm template
        run: |
          cd application/helm
          helm template test . --debug --dry-run

      - name: Validate Ansible syntax
        run: |
          pip install ansible
          cd infrastructure/ansible
          ansible-playbook --syntax-check provision-infrastructure.yml
          ansible-playbook --syntax-check setup-cluster.yml

  # ============= BUILD & PUSH =============
  build-and-push:
    name: Build & Push Docker Image
    needs: [lint-and-test, validate-manifests]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      security-events: write
    outputs:
      image-tag: ${{ steps.meta.outputs.version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: ./application/api
          push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Run Trivy security scan
        id: trivy
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: aquasecurity/trivy-action@0.33.1
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          format: "sarif"
          output: "trivy-results.sarif"

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always() && steps.trivy.outcome != 'skipped'
        with:
          sarif_file: "trivy-results.sarif"

  # ============= INFRASTRUCTURE DEPLOYMENT =============
  deploy-infrastructure:
    name: Deploy Infrastructure
    needs: build-and-push
    if: github.event.inputs.deploy_infrastructure == 'true'
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Setup Ansible
        run: pip install ansible

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts || true
          # Generate public key from private key for cloud-init injection
          ssh-keygen -y -f ~/.ssh/id_ed25519 > ~/.ssh/id_ed25519.pub

      - name: Terraform Init
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_S3_SECRET_KEY }}
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          cd infrastructure/terraform
          terraform init -reconfigure

      - name: Terraform Plan
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_S3_SECRET_KEY }}
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          cd infrastructure/terraform
          SSH_PUBLIC_KEY=$(cat ~/.ssh/id_ed25519.pub)
          terraform plan \
            -var="arvan_api_key=${{ secrets.ARVAN_API_KEY }}" \
            -var="ssh_public_key=${SSH_PUBLIC_KEY}" \
            -out=tfplan

      - name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_S3_SECRET_KEY }}
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          cd infrastructure/terraform
          terraform apply -auto-approve tfplan

      - name: Get Public IPs from ArvanCloud API
        env:
          ARVAN_API_KEY: ${{ secrets.ARVAN_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_S3_SECRET_KEY }}
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          cd infrastructure/terraform

          # Get server IDs from terraform
          MASTER_ID=$(terraform output -raw master_id)
          WORKER_IDS=$(terraform output -json worker_ids | jq -r '.[]')
          REGION=$(terraform output -raw region 2>/dev/null || echo "ir-thr-c2")

          echo "Master ID: $MASTER_ID"
          echo "Worker IDs: $WORKER_IDS"

          # Function to get public IP from ArvanCloud API
          get_public_ip() {
            local server_id=$1
            local response=$(curl -s -H "Authorization: $ARVAN_API_KEY" \
              "https://napi.arvancloud.ir/ecc/v1/regions/${REGION}/servers/${server_id}")

            # Extract public IPv4 address
            local public_ip=$(echo "$response" | jq -r '.data.addresses | to_entries[] | .value[] | select(.version == "4" and .is_public == true) | .addr' | head -1)

            if [ -z "$public_ip" ] || [ "$public_ip" == "null" ]; then
              # Fallback: try to get any public address
              public_ip=$(echo "$response" | jq -r '.data.addresses | to_entries[] | .value[] | select(.is_public == true) | .addr' | head -1)
            fi

            echo "$public_ip"
          }

          # Get master public IP and password
          MASTER_PUBLIC_IP=$(get_public_ip "$MASTER_ID")
          MASTER_PASSWORD=$(terraform state show module.compute.arvan_abrak.k8s_master | grep 'password' | awk -F'"' '{print $2}')
          echo "Master Public IP: $MASTER_PUBLIC_IP"

          # Get worker public IPs and passwords
          WORKER_PUBLIC_IPS=""
          WORKER_PASSWORDS=""
          worker_index=0
          for worker_id in $WORKER_IDS; do
            worker_ip=$(get_public_ip "$worker_id")
            worker_password=$(terraform state show "module.compute.arvan_abrak.k8s_worker[$worker_index]" | grep 'password' | awk -F'"' '{print $2}')
            echo "Worker $worker_index Public IP: $worker_ip"

            if [ -n "$WORKER_PUBLIC_IPS" ]; then
              WORKER_PUBLIC_IPS="$WORKER_PUBLIC_IPS,$worker_ip"
              WORKER_PASSWORDS="$WORKER_PASSWORDS,$worker_password"
            else
              WORKER_PUBLIC_IPS="$worker_ip"
              WORKER_PASSWORDS="$worker_password"
            fi
            worker_index=$((worker_index + 1))
          done

          # Save IPs and passwords to files for later steps
          echo "$MASTER_PUBLIC_IP" > /tmp/master_public_ip
          echo "$MASTER_PASSWORD" > /tmp/master_password
          echo "$WORKER_PUBLIC_IPS" > /tmp/worker_public_ips
          echo "$WORKER_PASSWORDS" > /tmp/worker_passwords

          echo "=== Public IPs ==="
          echo "Master: $MASTER_PUBLIC_IP"
          echo "Workers: $WORKER_PUBLIC_IPS"

      - name: Create SSH setup script
        run: |
          cat > /tmp/setup_ssh.sh << 'SCRIPT_EOF'
          #!/bin/bash
          set -e

          IP=$1
          OLD_PASSWORD=$2
          NEW_PASSWORD=$3
          SSH_PUBLIC_KEY=$4
          NAME=$5

          echo "Setting up $NAME ($IP)..."

          # Wait for SSH port to be available
          for i in {1..30}; do
            if nc -z -w5 $IP 22 2>/dev/null; then
              echo "SSH port is open on $NAME"
              break
            fi
            echo "Attempt $i/30: Waiting for SSH port on $NAME..."
            sleep 10
          done

          # Create expect script for password change and SSH key injection
          cat > /tmp/expect_script_$$.exp << EXPECT_SCRIPT
          #!/usr/bin/expect -f
          set timeout 120
          set ip [lindex \$argv 0]
          set old_pass [lindex \$argv 1]
          set new_pass [lindex \$argv 2]
          set ssh_key [lindex \$argv 3]

          # First connection - handle password change
          spawn ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ubuntu@\$ip

          expect {
              -re "password:" {
                  send "\$old_pass\r"
                  exp_continue
              }
              -re "Current password:" {
                  send "\$old_pass\r"
                  exp_continue
              }
              -re "New password:" {
                  send "\$new_pass\r"
                  exp_continue
              }
              -re "Retype new password:" {
                  send "\$new_pass\r"
                  exp_continue
              }
              -re "passwd: password updated successfully" {
                  puts "Password changed successfully"
                  exp_continue
              }
              -re "Connection.*closed" {
                  puts "Connection closed after password change"
              }
              -re "\\\$|#" {
                  send "exit\r"
                  expect eof
              }
              timeout {
                  puts "Timeout on first connection"
                  exit 1
              }
              eof {
                  puts "Connection closed"
              }
          }

          sleep 3

          # Second connection - inject SSH key
          spawn ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ubuntu@\$ip

          expect {
              -re "password:" {
                  send "\$new_pass\r"
                  exp_continue
              }
              -re "\\\$|#" {
                  send "mkdir -p ~/.ssh && chmod 700 ~/.ssh\r"
                  expect -re "\\\$|#"
                  send "echo '\$ssh_key' >> ~/.ssh/authorized_keys\r"
                  expect -re "\\\$|#"
                  send "chmod 600 ~/.ssh/authorized_keys\r"
                  expect -re "\\\$|#"
                  send "sudo mkdir -p /root/.ssh && sudo chmod 700 /root/.ssh\r"
                  expect -re "\\\$|#"
                  send "echo '\$ssh_key' | sudo tee -a /root/.ssh/authorized_keys\r"
                  expect -re "\\\$|#"
                  send "sudo chmod 600 /root/.ssh/authorized_keys\r"
                  expect -re "\\\$|#"
                  send "echo 'SSH key injected successfully'\r"
                  expect -re "\\\$|#"
                  send "exit\r"
                  expect eof
              }
              timeout {
                  puts "Timeout on second connection"
                  exit 1
              }
          }

          puts "Setup complete"
          EXPECT_SCRIPT

          chmod +x /tmp/expect_script_$$.exp
          /tmp/expect_script_$$.exp "$IP" "$OLD_PASSWORD" "$NEW_PASSWORD" "$SSH_PUBLIC_KEY"
          rm -f /tmp/expect_script_$$.exp

          echo "Setup complete for $NAME"
          SCRIPT_EOF
          chmod +x /tmp/setup_ssh.sh

      - name: Install sshpass and inject SSH keys
        run: |
          # Install sshpass and expect for password-based SSH and password change
          sudo apt-get update && sudo apt-get install -y sshpass expect netcat-openbsd

          # Read IPs and passwords
          MASTER_IP=$(cat /tmp/master_public_ip)
          MASTER_PASSWORD=$(cat /tmp/master_password)
          WORKER_IPS=$(cat /tmp/worker_public_ips | tr ',' '\n')
          WORKER_PASSWORDS=$(cat /tmp/worker_passwords | tr ',' '\n')

          SSH_PUBLIC_KEY=$(cat ~/.ssh/id_ed25519.pub)
          NEW_PASSWORD="K8s@Secure2025!"

          # Setup master
          /tmp/setup_ssh.sh "$MASTER_IP" "$MASTER_PASSWORD" "$NEW_PASSWORD" "$SSH_PUBLIC_KEY" "Master node"

          # Setup workers
          readarray -t WORKER_IP_ARRAY <<< "$WORKER_IPS"
          readarray -t WORKER_PASS_ARRAY <<< "$WORKER_PASSWORDS"

          for i in "${!WORKER_IP_ARRAY[@]}"; do
            if [ -n "${WORKER_IP_ARRAY[$i]}" ]; then
              /tmp/setup_ssh.sh "${WORKER_IP_ARRAY[$i]}" "${WORKER_PASS_ARRAY[$i]}" "$NEW_PASSWORD" "$SSH_PUBLIC_KEY" "Worker $i"
            fi
          done

          echo "SSH keys injected to all servers"

      - name: Wait for servers to be reachable
        run: |
          # Read IPs from files
          MASTER_IP=$(cat /tmp/master_public_ip)
          WORKER_IPS=$(cat /tmp/worker_public_ips | tr ',' '\n')

          echo "Master public IP: $MASTER_IP"
          echo "Worker public IPs: $WORKER_IPS"

          # Function to wait for a server to be reachable via SSH (try both ubuntu and root)
          wait_for_ssh() {
            local ip=$1
            local name=$2
            echo "Waiting for $name ($ip) to be reachable via SSH..."
            for i in {1..60}; do
              # Try root first (preferred for Ansible)
              if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes root@$ip "echo 'SSH connection successful'" 2>/dev/null; then
                echo "$name is reachable via SSH as root!"
                return 0
              fi
              # Try ubuntu user as fallback
              if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes ubuntu@$ip "echo 'SSH connection successful'" 2>/dev/null; then
                echo "$name is reachable via SSH as ubuntu!"
                return 0
              fi
              echo "Attempt $i/60: $name not reachable yet, waiting..."
              sleep 10
            done
            echo "WARNING: $name may not be fully ready after 10 minutes"
            return 1
          }

          # Wait for master node
          wait_for_ssh "$MASTER_IP" "Master node"

          # Wait for each worker node
          for WORKER_IP in $WORKER_IPS; do
            if [ -n "$WORKER_IP" ]; then
              wait_for_ssh "$WORKER_IP" "Worker node"
            fi
          done

          echo "All servers are reachable. Waiting additional 30 seconds for system initialization..."
          sleep 30

      - name: Generate Ansible Inventory
        run: |
          # Read IPs from files
          MASTER_IP=$(cat /tmp/master_public_ip)
          WORKER_IPS=$(cat /tmp/worker_public_ips)

          echo "=== Generating Ansible Inventory ==="
          echo "Master IP: $MASTER_IP"
          echo "Worker IPs: $WORKER_IPS"

          cd infrastructure/ansible

          # Check if root SSH works, otherwise use ubuntu with become
          if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes root@$MASTER_IP "echo test" 2>/dev/null; then
            ANSIBLE_USER="root"
            BECOME_LINE=""
          else
            ANSIBLE_USER="ubuntu"
            BECOME_LINE="ansible_become=yes ansible_become_method=sudo"
          fi

          echo "Using Ansible user: $ANSIBLE_USER"

          # Generate inventory file with proper formatting
          echo "[k8s_master]" > inventory.ini
          echo "master ansible_host=${MASTER_IP} ansible_user=${ANSIBLE_USER} ansible_ssh_private_key_file=~/.ssh/id_ed25519 ${BECOME_LINE}" >> inventory.ini

          echo "" >> inventory.ini
          echo "[k8s_workers]" >> inventory.ini

          # Add worker entries
          IFS=',' read -ra WORKER_ARRAY <<< "$WORKER_IPS"
          for i in "${!WORKER_ARRAY[@]}"; do
            echo "worker${i} ansible_host=${WORKER_ARRAY[$i]} ansible_user=${ANSIBLE_USER} ansible_ssh_private_key_file=~/.ssh/id_ed25519 ${BECOME_LINE}" >> inventory.ini
          done

          echo "" >> inventory.ini
          echo "[k8s:children]" >> inventory.ini
          echo "k8s_master" >> inventory.ini
          echo "k8s_workers" >> inventory.ini

          echo "=== Generated inventory.ini ==="
          cat inventory.ini

      - name: Add hosts to known_hosts
        run: |
          # Read IPs from files
          MASTER_IP=$(cat /tmp/master_public_ip)
          WORKER_IPS=$(cat /tmp/worker_public_ips | tr ',' '\n')

          echo "Adding master ($MASTER_IP) to known_hosts"
          ssh-keyscan -H $MASTER_IP >> ~/.ssh/known_hosts 2>/dev/null || true

          for ip in $WORKER_IPS; do
            if [ -n "$ip" ]; then
              echo "Adding worker ($ip) to known_hosts"
              ssh-keyscan -H $ip >> ~/.ssh/known_hosts 2>/dev/null || true
            fi
          done

      - name: Deploy Kubernetes Cluster
        run: |
          cd infrastructure/ansible
          ansible-playbook -i inventory.ini setup-cluster.yml

      - name: Setup kubectl
        run: |
          mkdir -p ~/.kube
          MASTER_IP=$(cat /tmp/master_public_ip)
          # Try root first, then ubuntu
          if scp -o StrictHostKeyChecking=no -o BatchMode=yes root@$MASTER_IP:~/.kube/config ~/.kube/config 2>/dev/null; then
            echo "Copied kubeconfig as root"
          else
            scp -o StrictHostKeyChecking=no ubuntu@$MASTER_IP:~/.kube/config ~/.kube/config
            echo "Copied kubeconfig as ubuntu"
          fi
          sed -i "s/127.0.0.1/$MASTER_IP/g" ~/.kube/config
          kubectl get nodes

      - name: Deploy Monitoring Stack
        run: |
          cd infrastructure/ansible
          ansible-playbook -i inventory.ini deploy-monitoring.yml \
            -e "grafana_admin_password=${{ secrets.GRAFANA_PASSWORD }}"

      - name: Deploy PostgreSQL
        run: |
          cd infrastructure/ansible
          ansible-playbook -i inventory.ini deploy-postgres.yml

  # ============= APPLICATION DEPLOYMENT =============
  deploy-application:
    name: Deploy Application
    needs: build-and-push
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4

      - name: Setup kubeconfig
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > ~/.kube/config

      - name: Setup Helm
        uses: azure/setup-helm@v4

      - name: Create namespace
        run: |
          kubectl create namespace application --dry-run=client -o yaml | kubectl apply -f -

      - name: Create secrets
        run: |
          kubectl create secret generic postgres-secret \
            --from-literal=username="${{ secrets.DB_USERNAME }}" \
            --from-literal=password="${{ secrets.DB_PASSWORD }}" \
            --from-literal=database="${{ secrets.DB_NAME }}" \
            --namespace=application \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy application with Helm
        run: |
          cd application/helm
          helm dependency update
          helm upgrade --install api . \
            --namespace application \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=latest \
            --set database.host=postgres-service \
            --set database.port=5432 \
            --wait --timeout 5m

      - name: Verify deployment
        run: |
          kubectl rollout status deployment/api -n application --timeout=5m
          kubectl get pods -n application
          kubectl get svc -n application

      - name: Run smoke tests
        run: |
          API_URL=$(kubectl get svc api -n application -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          if [ -z "$API_URL" ]; then
            API_URL=$(kubectl get svc api -n application -o jsonpath='{.spec.clusterIP}')
          fi
          kubectl run curl-test --image=curlimages/curl:latest --rm -i --restart=Never -- \
            curl -f http://$API_URL:80/health || exit 1
  # ============= GITOPS SYNC (Optional) =============
  sync-argocd:
    name: Sync ArgoCD Applications
    needs: build-and-push
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install ArgoCD CLI
        run: |
          curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
          chmod +x argocd
          sudo mv argocd /usr/local/bin/

      - name: Login to ArgoCD
        run: |
          argocd login ${{ secrets.ARGOCD_SERVER }} \
            --username admin \
            --password ${{ secrets.ARGOCD_PASSWORD }} \
            --insecure

      - name: Sync applications
        run: |
          argocd app sync ip-geolocation-api --async
          argocd app sync monitoring-stack --async

      - name: Wait for sync
        run: |
          argocd app wait ip-geolocation-api --timeout 300
          argocd app wait monitoring-stack --timeout 300
